{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75857950",
   "metadata": {},
   "source": [
    "# Query Multiple Files with `GPT`\n",
    "ðŸ““ Notebook from [gkamradt](https://github.com/gkamradt/langchain-tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51b805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install python-magic-bin\n",
    "#!pip install chromadb\n",
    "#!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63088e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import magic\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = '...'\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# pip install unstructured\n",
    "# Other dependencies to install https://langchain.readthedocs.io/en/latest/modules/document_loaders/examples/unstructured_file.html\n",
    "# pip install python-magic-bin\n",
    "# pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dcb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a28a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Luke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('data/PaulGrahamEssaySmall/', glob='**/*.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3153f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cad0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734ed265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817a0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3.9\\envs\\lukebot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:152: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5533a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McCarthy discovered that, given a handful of simple operators and\n",
      "a notation for functions, you can build a whole programming\n",
      "language which he called Lisp. He also used a simple\n",
      "data structure called a list for both code and data.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did McCarthy discover?\"\n",
    "ans = qa.run(query)\n",
    "\n",
    "ans = ans.split()\n",
    "for i in range(0, len(ans), 10):\n",
    "    print(' '.join(ans[i:i+10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f22231c5",
   "metadata": {},
   "source": [
    "### `Langchain` return Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "694343cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3.9\\envs\\lukebot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:152: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
    "query = \"What did McCarthy discover?\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec53323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' McCarthy discovered a way to create a whole programming language out of a handful of simple operators and a notation for functions. He called this language Lisp.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32246ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='May 2001\\n\\n(I wrote this article to help myself understand exactly\\n\\nwhat McCarthy discovered.  You don\\'t need to know this stuff\\n\\nto program in Lisp, but it should be helpful to\\n\\nanyone who wants to\\n\\nunderstand the essence of Lisp \\x97 both in the sense of its\\n\\norigins and its semantic core.  The fact that it has such a core\\n\\nis one of Lisp\\'s distinguishing features, and the reason why,\\n\\nunlike other languages, Lisp has dialects.)In 1960, John\\n\\nMcCarthy published a remarkable paper in\\n\\nwhich he did for programming something like what Euclid did for\\n\\ngeometry. He showed how, given a handful of simple\\n\\noperators and a notation for functions, you can\\n\\nbuild a whole programming language.\\n\\nHe called this language Lisp, for \"List Processing,\"\\n\\nbecause one of his key ideas was to use a simple\\n\\ndata structure called a list for both\\n\\ncode and data.It\\'s worth understanding what McCarthy discovered, not\\n\\njust as a landmark in the history of computers, but as', lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\rootsoflisp.txt'}, lookup_index=0),\n",
       " Document(page_content=\"itself.  To understand what McCarthy meant by this,\\n\\nwe're going to retrace his steps, with his mathematical\\n\\nnotation translated into running Common Lisp code.\", lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\rootsoflisp.txt'}, lookup_index=0),\n",
       " Document(page_content=\"a model for what programming is tending to become in\\n\\nour own time.  It seems to me that there have been\\n\\ntwo really clean, consistent models of programming so\\n\\nfar: the C model and the Lisp model.\\n\\nThese two seem points of high ground, with swampy lowlands\\n\\nbetween them.  As computers have grown more powerful,\\n\\nthe new languages being developed have been moving\\n\\nsteadily toward the Lisp model.  A popular recipe\\n\\nfor new programming languages in the past 20 years\\n\\nhas been to take the C model of computing and add to\\n\\nit, piecemeal, parts taken from the Lisp model,\\n\\nlike runtime typing and garbage collection.In this article I'm going to try to explain in the\\n\\nsimplest possible terms what McCarthy discovered.\\n\\nThe point is not just to learn about an interesting\\n\\ntheoretical result someone figured out forty years ago,\\n\\nbut to show where languages are heading.\\n\\nThe unusual thing about Lisp \\x97 in fact, the defining\\n\\nquality of Lisp \\x97 is that it can be written in\", lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\rootsoflisp.txt'}, lookup_index=0),\n",
       " Document(page_content=\"January 2023(Someone fed my essays into GPT to make something that could answer\\n\\nquestions based on them, then asked it where good ideas come from.  The\\n\\nanswer was ok, but not what I would have said. This is what I would have said.)The way to get new ideas is to notice anomalies: what seems strange,\\n\\nor missing, or broken? You can see anomalies in everyday life (much\\n\\nof standup comedy is based on this), but the best place to look for\\n\\nthem is at the frontiers of knowledge.Knowledge grows fractally.\\n\\nFrom a distance its edges look smooth, but when you learn enough\\n\\nto get close to one, you'll notice it's full of gaps. These gaps\\n\\nwill seem obvious; it will seem inexplicable that no one has tried\\n\\nx or wondered about y. In the best case, exploring such gaps yields\\n\\nwhole new fractal buds.\", lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\getideas.txt'}, lookup_index=0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1415339",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
    "query = \"What is the biggest town between Christchurch and Dunedin?\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad9ee33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the biggest town between Christchurch and Dunedin?',\n",
       " 'result': ' Oamaru is the biggest town between Christchurch and Dunedin.',\n",
       " 'source_documents': [Document(page_content='made clear, is to talk confidently about things they don\\'t\\n\\nunderstand.An event like this is thus a uniquely powerful way of taking people\\'s\\n\\nmeasure. As Warren Buffett said, \"It\\'s only when the tide goes out\\n\\nthat you learn who\\'s been swimming naked.\" And the tide has just\\n\\ngone out like never before.Now that we\\'ve seen the results, let\\'s remember what we saw, because\\n\\nthis is the most accurate test of credibility we\\'re ever likely to have. I hope.', lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\cred.txt'}, lookup_index=0),\n",
       "  Document(page_content=\"April 2012A palliative care nurse called Bronnie Ware made a list of the\\n\\nbiggest regrets\\n\\nof the dying.  Her list seems plausible.  I could see\\n\\nmyself â€” can see myself â€” making at least 4 of these\\n\\n5 mistakes.If you had to compress them into a single piece of advice, it might\\n\\nbe: don't be a cog.  The 5 regrets paint a portrait of post-industrial\\n\\nman, who shrinks himself into a shape that fits his circumstances,\\n\\nthen turns dutifully till he stops.The alarming thing is, the mistakes that produce these regrets are\\n\\nall errors of omission.  You forget your dreams, ignore your family,\\n\\nsuppress your feelings, neglect your friends, and forget to be\\n\\nhappy.  Errors of omission are a particularly dangerous type of\\n\\nmistake, because you make them by default.I would like to avoid making these mistakes.  But how do you avoid\\n\\nmistakes you make by default?  Ideally you transform your life so\\n\\nit has other defaults.  But it may not be possible to do that\", lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\todo.txt'}, lookup_index=0),\n",
       "  Document(page_content=\"January 2023(Someone fed my essays into GPT to make something that could answer\\n\\nquestions based on them, then asked it where good ideas come from.  The\\n\\nanswer was ok, but not what I would have said. This is what I would have said.)The way to get new ideas is to notice anomalies: what seems strange,\\n\\nor missing, or broken? You can see anomalies in everyday life (much\\n\\nof standup comedy is based on this), but the best place to look for\\n\\nthem is at the frontiers of knowledge.Knowledge grows fractally.\\n\\nFrom a distance its edges look smooth, but when you learn enough\\n\\nto get close to one, you'll notice it's full of gaps. These gaps\\n\\nwill seem obvious; it will seem inexplicable that no one has tried\\n\\nx or wondered about y. In the best case, exploring such gaps yields\\n\\nwhole new fractal buds.\", lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\getideas.txt'}, lookup_index=0),\n",
       "  Document(page_content='After a link to\\n\\nBeating the Averages was posted on slashdot,\\n\\nsome readers wanted to hear in more detail\\n\\nabout the specific technical advantages we got from using\\n\\nLisp in Viaweb.  For those who are interested,\\n\\nhere are some excerpts from a talk I gave in April 2001 at\\n\\nBBN Labs in Cambridge, MA.', lookup_str='', metadata={'source': 'data\\\\PaulGrahamEssaySmall\\\\lwba.txt'}, lookup_index=0)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c457d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
